# ç¨³å®šæ‰©æ•£æ¨¡å‹ï¼ˆStable Diffusion Modelsï¼‰

åœ¨ä¹‹å‰å·²ç»äº†è§£åˆ°äº†DDPMä»¥åŠDDIMç­‰æ‰©æ•£æ¨¡å‹ã€‚ä½†è¿™äº›æ¨¡å‹æœ‰ä»¥ä¸‹ä¸¤ä¸ªç¼ºç‚¹ï¼š

1. æ¨¡å‹è¾“å‡ºçš„å›¾ç‰‡æ˜¯ä¸å¯æ§çš„ï¼Œæ— æ³•æ§åˆ¶æ¨¡å‹è¾“å‡ºæƒ³è¦çš„å›¾ç‰‡ï¼›
2. æ¨¡å‹è¾“å…¥å°ºå¯¸çš„å¤§å°å’Œæ¨¡å‹è¾“å‡ºå›¾ç‰‡çš„å¤§å°ç›¸åŒï¼Œå½“è¾“å‡ºå›¾ç‰‡çš„å°ºå¯¸è¾ƒå¤§æ—¶ï¼Œæ¨¡å‹å°±ä¼šéå¸¸æ¶ˆè€—èµ„æºã€‚

ç¨³å®šæ‰©æ•£æ¨¡å‹ä¸­æ·»åŠ äº†**æ¡ä»¶æ§åˆ¶**ç”¨äºæ§åˆ¶æ¨¡å‹çš„è¾“å‡ºï¼Œå°†æ¨¡å‹çš„è¾“å…¥å‹ç¼©æˆ**æ½œåœ¨ç©ºé—´**æ¥å‡å°‘èµ„æºçš„æ¶ˆè€—ã€‚ç¨³å®šæ‰©æ•£æ¨¡å‹ (Stable Diffusion Models) ä¹Ÿå±äºæ½œåœ¨æ‰©æ•£æ¨¡å‹ (Latent Diffusion Models, LDM)ã€‚

## 1. æ¡ä»¶æ§åˆ¶æ‰©æ•£æ¨¡å‹ï¼ˆConditional Diffusion Modelsï¼‰

DDPMã€DDIMç­‰æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä¸€å¼ å›¾ç‰‡æ—¶ï¼Œè¾“å…¥ä¸ºä¸€å¼ éšæœºçš„æ ‡å‡†é«˜æ–¯å™ªå£°æ•°æ®ï¼Œç„¶åè¿­ä»£ä¸€æ­¥æ­¥ç”Ÿæˆä¸€å¼ å›¾ç‰‡ã€‚ä½†æ˜¯ç”Ÿæˆçš„å›¾ç‰‡æ¯ä¸€æ­¥éƒ½æ˜¯éšæœºè¿‡ç¨‹ï¼Œå› æ­¤æ¯æ¬¡ç”Ÿæˆçš„å›¾ç‰‡éƒ½æ˜¯ä¸ä¸€æ ·çš„ï¼ˆç”±éšæœºå™ªå£°$\ \sigma_t\epsilon$å¯¼è‡´çš„ï¼‰ï¼Œç”Ÿæˆçš„å›¾ç‰‡æ›´åŠ çš„å¤šæ ·æ€§ï¼›å½“éšæœºå™ªå£°$\ \sigma_t\epsilon$ ä¸º$\ 0$ æ—¶ï¼Œç”Ÿæˆçš„å›¾ç‰‡æ˜¯å›ºå®šçš„ï¼Œä½†ä¸ä¸€å®šæ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚ä¸ºäº†æ§åˆ¶æ¨¡å‹çš„è¾“å‡ºï¼Œå¯ä»¥åŠ å…¥ä¸€ä¸ªé¢å¤–çš„ä¿¡æ¯$\ y$ æ¥æŒ‡å¯¼æˆ–æ§åˆ¶è¾“å‡ºç»“æœï¼Œè¿™ä¸ªé¢å¤–ä¿¡æ¯$\ y$ å¯ä»¥æ˜¯ä¸€æ®µæ–‡æœ¬ã€ä¸€å¼ å›¾ç‰‡æˆ–æ˜¯å›¾åƒæ ‡ç­¾ã€‚åœ¨å¼•å…¥$\ y$ åï¼Œæ¨¡å‹çš„æ¡æ¦‚ç‡åˆ†å¸ƒå°±ä¼šå˜ä¸ºï¼š
$$
p(x_{1:T}|y, x_0)
$$
å¼•å…¥$\ y$ åæ¨¡å‹è¾“å…¥æ•°æ®å°±å˜ä¸º$\ (x_0, y)$ ï¼Œç±»ä¼¼å›¾åƒåˆ†ç±»çš„æ•°æ®æ ‡ç­¾ã€‚æ¨¡å‹çš„å‘å‰æ‰©æ•£è¿‡ç¨‹æ˜¯ä¸€æ­¥æ­¥æ·»åŠ å™ªå£°ï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªéšæœºé«˜æ–¯å™ªå£°ï¼Œè¿™ä¸€è¿‡ç¨‹ä¸­å¹¶æ²¡æœ‰ç”¨åˆ°é¢å¤–ä¿¡æ¯$\ y$ ã€‚å› æ­¤ï¼Œå¼•å…¥é¢å¤–ä¿¡æ¯$\ y$â€‹ å¯¹å‘å‰æ‰©æ•£å¹¶æ²¡æœ‰å½±å“ï¼Œå³**æ¡ä»¶æ§åˆ¶æ‰©æ•£æ¨¡å‹çš„å‰å‘è¿‡ç¨‹ä¸éæ¡ä»¶æ§åˆ¶æ‰©æ•£æ¨¡å‹çš„å‰å‘è¿‡ç¨‹å®Œå…¨ä¸€æ ·**ã€‚

æˆ‘ä»¬å¸Œæœ›é¢å¤–ä¿¡æ¯$\ y$ èƒ½å¤Ÿæ§åˆ¶é€†å‘é‡‡æ ·ç”Ÿæˆçš„å›¾ç‰‡ã€‚å› æ­¤ï¼Œ$\ y$ è‚¯å®šä¼šå¯¹é€†å‘è¿‡ç¨‹äº§ç”Ÿå½±å“ï¼›æ­¤æ—¶ï¼Œé€†å‘è¿‡ç¨‹çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒå°±ä¼šå˜ä¸ºï¼š
$$
q_{\sigma}(x_{t-1}|x_t, x_0, y) \approx p_{\sigma, \theta}(x_{t-1}|x_t, y) \quad \sigma ä¸ºè¶…å‚æ•°
$$
åœ¨è®²éæ¡ä»¶æ§åˆ¶æ‰©æ•£æ¨¡å‹æ—¶ï¼Œå¯¹äº$\ p_{\sigma, \theta}(x_{t-1}|x_t)$ çš„é¢„æµ‹ç”±ä¸‰ç§æ–¹æ¡ˆï¼š

1. ç›´æ¥é¢„æµ‹åŸå§‹$\ x_0$ï¼Œ$\ {x_{\theta}}(x_t, t) \approx x_0$ ï¼›
2. é¢„æµ‹ä»$\ x_0$ åˆ°$\ x_t$ æ·»åŠ çš„å™ªå£°$\ \epsilon$ ï¼Œ$\ \epsilon_{\theta}(x_t, t) \approx \epsilon$â€‹;
3. é¢„æµ‹å¾—åˆ†ï¼ˆæ¢¯åº¦ï¼‰ï¼Œ$\ s_{\theta}(x_t, t) \approx \nabla_{x_t}\log p(x_t)$â€‹ã€‚

å¦‚ä½•å¼•å…¥é¢å¤–ä¿¡æ¯$\ y$ï¼Œæ¯”è¾ƒç®€å•çš„æ–¹å¼å°±æ˜¯å°†$\ y$ ä¹Ÿä½œä¸ºæ¨¡å‹çš„è¾“å…¥æ¥æ§åˆ¶ç”Ÿæˆçš„ç»“æœï¼š

1. ç›´æ¥é¢„æµ‹åŸå§‹$\ x_0$ï¼Œ$\ {x_{\theta}}(x_t, t, y) \approx x_0$ ï¼›
2. é¢„æµ‹ä»$\ x_0$ åˆ°$\ x_t$ æ·»åŠ çš„å™ªå£°$\ \epsilon$ ï¼Œ$\ \epsilon_{\theta}(x_t, t, y) \approx \epsilon$â€‹;
3. é¢„æµ‹å¾—åˆ†ï¼ˆæ¢¯åº¦ï¼‰ï¼Œ$\ s_{\theta}(x_t, t, y) \approx \nabla_{x_t}\log p(x_t)$â€‹â€‹ã€‚

ä¸‹é¢çœ‹çœ‹å…·ä½“æ–¹æ¡ˆguidanceæ˜¯æ€ä¹ˆå¼•å…¥é¢å¤–ä¿¡æ¯$\ y$ çš„ã€‚

### Classifier guidance

classifier guidance å³åˆ†ç±»å¼•å¯¼å™¨ã€‚åœ¨ä¸Šè¿°è®²æ¨¡å‹é¢„æµ‹çš„ä¸‰ç§æ–¹æ¡ˆä¸­å°±æåˆ°äº†é¢„æµ‹å¾—åˆ†ï¼ˆæ¢¯åº¦ï¼‰ï¼Œå³ç¥ç»ç½‘ç»œçš„è¾“å‡ºç»“æœ$\ s_{\theta}(x_t, t)$ é¢„æµ‹$\ \nabla_{x_t}\log p(x_t)$ ã€‚åœ¨å¼•å…¥æ¡ä»¶ä¿¡æ¯$\ y$ åï¼Œç¥ç»ç½‘ç»œå°±å˜ä¸ºé¢„æµ‹$\ \nabla_{x_t}\log p(x_t|y)$ ï¼ˆæŒ‡åœ¨æ¡ä»¶$\ y$ ä¸‹ç”Ÿæˆ$\ x_t$ çš„å¯¹æ•°æ¡ä»¶æ¦‚ç‡çš„æ¢¯åº¦ï¼‰ï¼Œæ‰€ä»¥åªéœ€è¦æ¨å¯¼å‡º$\ \nabla_{x_t}\log p(x_t|y)$ å³å¯ï¼š
$$
\begin{aligned}
\nabla_{x_t}\log p(x_t|y) &= \nabla_{x_t}\log \left(\frac{p(x_t)p(y|x_t)}{p(y)} \right) \\
&= \nabla_{x_t}\log p(x_t) + \nabla_{x_t}\log p(y|x_t) - \underbrace{\nabla_{x_t}\log p(y)}_{ä¸x_tæ— å…³ï¼Œæ¢¯åº¦ä¸º0} \\
&= \underbrace{\nabla_{x_t}\log p(x_t)}_{unconditional\ score} + \underbrace{\nabla_{x_t}\log p(y|x_t)}_{adversarial\ gradient}
\end{aligned}
$$
å…¶ä¸­ï¼Œ$\ \nabla_{x_t}\log p(x_t)$ å°±æ˜¯æ— æ¡ä»¶æ‰©æ•£æ¨¡å‹æœ¬èº«ï¼Œè¢«ç§°ä¸ºæ— æ¡ä»¶åˆ†æ•°ï¼ˆunconditional scoreï¼‰ï¼›$\ \nabla_{x_t}\log p(y|x_t)$ æ˜¯ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œ$\ x_t$ æ˜¯åˆ†ç±»å™¨çš„è¾“å…¥ï¼Œ$\ y$ ä¸ºåˆ†ç±»å™¨çš„è¾“å‡ºï¼Œè¿™ä¸€é¡¹è¢«ç§°ä¸ºå¯¹æŠ—æ¢¯åº¦ï¼ˆadversarial gradient)ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼š
$$
condition\ score = unconditional\ score + adbersarial\ gradient
$$
**åˆ†ç±»å™¨$\ \nabla_{x_t}\log p(y|x_t)$ éœ€è¦åœ¨è®­ç»ƒæ¡ä»¶æ‰©æ•£æ¨¡å‹ä¹‹å‰å•ç‹¬è®­ç»ƒå¥½çš„ã€‚**åˆ†ç±»å™¨çš„è¾“å…¥ä¸ºå‘å‰åŠ å™ªè¿‡ç¨‹ä¸­ç”Ÿæˆçš„$\ x_t$ ã€‚å®ç°å¦‚ä¸‹

1. è®­ç»ƒå¥½ä¸€ä¸ªå™ªå£°åˆ†ç±»å™¨$\ p(y|x_t)$ ;

2. åœ¨åŸæ¥éæ¡ä»¶æ‰©æ•£æ¨¡å‹çš„æ¯ä¸€æ—¶åˆ»$\ t$ çš„é‡‡æ ·è¿‡ç¨‹ä¸­:

   1). è®¡ç®—å‡ºæ¨¡å‹çš„é¢„æµ‹è¾“å‡º$\ s_{\theta}(x_t, t)$ ;

   2). è®²$\ x_t$ ä½œä¸ºåˆ†ç±»å™¨$\ p(y|x_t)$ çš„è¾“å…¥ï¼Œå¹¶è®¡ç®—å‡ºå¯¹æŠ—æ¢¯åº¦$\ \nabla_{x_t} \log p(y|x_t)$ï¼›

   3). è®¡ç®—$\ s_{\theta}(x_t, t, y) = s_{\theta}(x_t, t) + \nabla_{x_t}\log p(y|x_t)$ï¼›

   4). é€šè¿‡$\ s_{\theta}(x_t, t, y)$ è®¡ç®—å‡ºé€†å‘è¿‡ç¨‹$\ p_{\theta}(x_{t-1}|x_t, y)$ çš„å‡å€¼ï¼Œå¹¶è®¡ç®—å‡º$\ x_{t-1}$;

   5). å¦‚æ­¤åå¤ï¼ŒçŸ¥é“è®¡ç®—å‡º$\ x_0$â€‹ ã€‚

å¼•å…¥å¯¹æŠ—æ¢¯åº¦$\ \nabla_{x_t} \log p(y|x_t)$ ä¼šå½±å“é€†å‘é‡‡æ ·æ¨¡å‹æ¢¯åº¦çš„æ–¹å‘ï¼Œå›¾ç‰‡çš„é‡‡æ ·ä¼šæœç€$\ y$  çš„æ–¹å‘å‰è¿›ï¼Œæ¯”å¦‚å½“ å°ç‹—ğ‘¦="å°ç‹—" æ—¶ï¼Œ å°±ä¼šç”Ÿæˆæœ‰å°ç‹—çš„å›¾åƒï¼Œå¹¶ä¸”ç”Ÿæˆçš„å›¾åƒæ›´åŠ é€¼çœŸã€‚ç„¶è€Œå¼•å…¥ classifier guidance åï¼Œ**è™½ç„¶ç”Ÿæˆå›¾åƒçš„è´¨é‡æé«˜äº†ï¼Œæ›´åŠ é€¼çœŸï¼Œä½†æ˜¯æ˜¾ç„¶å®ƒä¼šé™ä½å¤šæ ·æ€§**ã€‚ä¸ºäº†æ›´åŠ çµæ´»çš„æ§åˆ¶è¾“å‡ºç»“æœï¼Œè®ºæ–‡ä¸­ç»™å¯¹æŠ—æ¢¯åº¦$\ \nabla_{x_t}\log p(y|x_t)$ æ·»åŠ äº†æƒé‡$\ \lambda$ ï¼Œè¿™ä¸ªæƒé‡æ˜¯äººå·¥å®šä¹‰çš„è¶…å‚æ•°ï¼Œæ˜¾ç„¶æƒé‡$\ \lambda$ å¯¹é€†å‘é‡‡æ ·çš„ç»“æœèµ·åˆ°äº†è°ƒèŠ‚ä½œç”¨ï¼š
$$
\nabla_{x_t}\log p(x_t|y) = \nabla_{x_t}\log p(x_t) + \lambda \nabla_{x_t}\log p(y|x_t)
$$
è™½ç„¶å¼•å…¥classifier guidanceï¼Œä½†æ˜¯ç¼ºç‚¹ä¹Ÿå¾ˆæ˜æ˜¾ï¼š

1. éœ€è¦é¢å¤–ä¸€ä¸ªåˆ†ç±»å™¨æ¨¡å‹ï¼Œæå¤§å¢åŠ äº†æˆæœ¬ï¼ŒåŒ…æ‹¬è®­ç»ƒæˆæœ¬å’Œé‡‡æ ·æˆæœ¬ï¼›
2. åˆ†ç±»å™¨çš„ç±»åˆ«æ¯•ç«Ÿæ˜¯æœ‰é™ï¼Œä¸èƒ½æ¶µç›–å…¨éƒ¨æƒ…å†µï¼Œå¯¹äºæ²¡æœ‰è¦†ç›–çš„æ ‡ç­¾ç±»åˆ«ä¼šå¾ˆä¸å‹å¥½ã€‚

### Classifier-free guidance

åœ¨å…¬å¼(3)ä¸­æˆ‘ä»¬å¾—å‡ºäº†ï¼š
$$
\nabla_{x_t} \log p(x_t|y) = \nabla_{x_t}\log p(x_t) + \nabla_{x_t}\log p(y|x_t)
$$
Classifier-free guidance å¯¹ Classifier guidance åšäº†äº›è®¸ä¿®æ”¹ï¼Œå¯¹å…¬å¼(6)è¿›è¡Œç§»é¡¹åï¼š
$$
\nabla_{x_t}\log p(y|x_t) = \nabla_{x_t}\log p(x_t|y) - \nabla_{x_t}\log p(x_t)
$$
å†æŠŠå…¬å¼(7)ä»£å…¥å…¬å¼(5)ä¸­å¾—ï¼š
$$
\begin{aligned}
\nabla_{x_t}\log p(x_t|y) &= \nabla_{x_t} \log p(x_t) + \lambda(\nabla_{x_t}\log p(x_t|y) - \nabla_{x_t}\log p(x_t)) \\ 
&= \underbrace{\lambda \nabla_{x_t}\log p(x_t|y)}_{conditional\ score} + \underbrace{(1-\lambda)\nabla_{x_t}\log p(x_t)}_{unconditional\ score}
\end{aligned}
$$
ç”±å…¬å¼(8)å¯ä»¥çœ‹å‡ºClassifier-free guidanceéœ€è¦è®­ç»ƒæ— æ¡ä»¶æ§åˆ¶æ¨¡å‹å’Œæ¡ä»¶æ§åˆ¶æ¨¡å‹ä¸¤ä¸ªæ¨¡å‹ï¼Œæ— éœ€é¢å¤–è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨å»å¼•å¯¼æ¨¡å‹é‡‡æ ·ç”Ÿæˆå¾—å›¾ç‰‡ï¼Œä½†æ˜¯æ¨¡å‹å¾—è®­ç»ƒä»£ä»·ä¹Ÿæ›´å¤§ï¼Œä½†æ•ˆæœä¹Ÿæ¯”Classifier guidanceæ›´å¥½ã€‚Stable Diffusionç”¨çš„å°±æ˜¯Classifier-free guidanceæ— åˆ†ç±»å™¨å¼•å¯¼å›¾ç‰‡ç”Ÿæˆã€‚



ç»¼ä¸Šï¼Œæˆ‘ä»¬å¯¹ä¸¤ç§æ¡ä»¶æ‰©æ•£æ¨¡å‹è¿›è¡Œ**æ€»ç»“**ï¼š

Classifier Guidanceï¼š

1. å¤–éƒ¨åˆ†ç±»å™¨ï¼šæˆ‘ä»¬éœ€è¦é¢å¤–è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ä¸ºç”Ÿæˆæ¨¡å‹æä¾›ç›®æ ‡ç±»åˆ«çš„ä¿¡æ¯ã€‚è¿™æ ·åšæå¤§å¢åŠ äº†æˆæœ¬ï¼ŒåŒ…æ‹¬è®­ç»ƒæˆæœ¬å’Œé‡‡æ ·æˆæœ¬ï¼›ä½†æ˜¯æˆ‘ä»¬ä¸éœ€è¦é‡æ–°è®­ç»ƒåŸå…ˆçš„ç”Ÿæˆæ¨¡å‹ã€‚
2. æ˜¾ç¤ºç”Ÿæˆï¼šå›¾åƒçš„ç”Ÿæˆè¿‡ç¨‹æ˜¾ç¤ºçš„ä¾èµ–åˆ†ç±»å™¨çš„è¾“å‡ºï¼Œæˆ‘ä»¬æä¾›æƒ³è¦ç”Ÿæˆçš„ç±»åˆ«ï¼Œç”Ÿæˆæ¨¡å‹ä¼šæ ¹æ®è¿™ä¸ªç±»åˆ«æ ‡ç­¾ç”Ÿæˆå›¾åƒã€‚ä½†æ˜¯åˆ†ç±»å™¨çš„ç±»åˆ«æœ‰é™ï¼Œä¸èƒ½æ¶µç›–å…¨éƒ¨æƒ…å†µï¼Œå¯¹äºæ²¡æœ‰è¦†ç›–çš„æ ‡ç­¾ç±»åˆ«ä¼šå¾ˆä¸å‹å¥½ã€‚

Classifier-Free Guidance:

1. é—´æ¥å¼•å¯¼ï¼šä¸éœ€è¦ç‹¬ç«‹çš„åˆ†ç±»å™¨æ¥æŒ‡å¯¼ç”Ÿæˆè¿‡ç¨‹ã€‚å®ƒä½¿ç”¨æ¨¡å‹å†…éƒ¨çš„ä¿¡æ¯æ¥å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼Œä¸éœ€è¦æ˜¾ç¤ºçš„ç±»åˆ«æ ‡ç­¾ï¼Œæ¨¡å‹å†…éƒ¨çš„ä¿¡æ¯å¯ä»¥æ›´åŠ å¤šæ ·ï¼Œå¦‚æ–‡æœ¬æè¿°ã€é£æ ¼ç‰¹å¾æˆ–å…¶ä»–å±æ€§ã€‚è¿™ç§å¼•å¯¼æ–¹å¼ç”Ÿæˆçš„å›¾åƒä¸å—ç‰¹å®šæ ‡ç­¾çš„é™åˆ¶ã€‚
2. ä»å…¬å¼(8)ä¸­å¯ä»¥çœ‹å‡ºï¼Œè¿™ç§ç”Ÿæˆæ¨¡å‹éœ€è¦è®­ç»ƒæ¡ä»¶ç”Ÿæˆæ¨¡å‹å’Œæ— æ¡ä»¶ç”Ÿæˆæ¨¡å‹ä¸¤ä¸ªæ¨¡å‹ï¼Œè®­ç»ƒçš„æˆæœ¬æ›´å¤§ã€‚ä½†åœ¨è¿™ä¸¤ä¸ªæ¨¡å‹å¯ä»¥ç”¨åŒä¸€ä¸ªæ¨¡å‹è¡¨ç¤ºï¼Œåœ¨Stable Diffusionè¿™ç§å°±æ˜¯å°†æ¨¡å‹çš„batchå˜ä¸º2ï¼Œä¸€ä¸ªbatchçš„è¾“å‡ºæ— æ¡ä»¶æ§åˆ¶çš„ç»“æœï¼Œå¦ä¸€ä¸ªbatchçš„è¾“å‡ºæ˜¯æœ‰æ¡ä»¶æ§åˆ¶çš„ç»“æœã€‚

## 2. æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLatent Diffusion Models, LDMï¼‰

### æ½œåœ¨ç©ºé—´

åœ¨DDPMä»¥åŠDDIMçš„é€†å‘é‡‡æ ·è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹çš„è¾“å…¥$\ x_t$ å’Œæ¨¡å‹çš„è¾“å‡º$\ x_0$ çš„å°ºå¯¸éƒ½æ˜¯ä¸€æ ·çš„ï¼Œå½“æˆ‘ä»¬æƒ³è¦è¾“å‡ºçš„å›¾ç‰‡$\ x_0$ çš„å°ºå¯¸è¾ƒå¤§æ—¶å°±ä¼šéå¸¸çš„æ¶ˆè€—ç¡¬ä»¶èµ„æºã€‚å¯¹äºè¿™ä¸ªé—®é¢˜å¯ä»¥å¼•å…¥ä¸€ä¸ªè‡ªç¼–ç å™¨ï¼ˆAutoencoderï¼‰ï¼Œå¦‚ä¸‹ï¼š

![image-20240423162339813](assets\image-20240423162339813-1713927210650-3.png)

è‡ªç¼–ç å™¨å°±æ˜¯å°†ä¸€å¼ å›¾ç‰‡$\ x_0$ å‹ç¼©æˆä½ç»´çš„$\ z_0$ ç„¶åå†è§£å‹æˆåŸå›¾å¤§å°$\ x^{\prime}_0$ ã€‚Autoencoder åŒ…å« **ç¼–ç å™¨E** å’Œ **è§£ç å™¨D** ä¸¤ä¸ªéƒ¨åˆ†ï¼š

- **ç¼–ç å™¨E**ï¼šå°† full-sized çš„å›¾ç‰‡å‹ç¼©æˆä½ç»´çš„æ½œåœ¨ç©ºé—´æ•°æ®ã€‚
- **è§£ç å™¨D**ï¼šå°†ä½ç»´æ½œåœ¨ç©ºé—´çš„å›¾ç‰‡è¿˜åŸæˆ full-sized å°ºå¯¸çš„å›¾ç‰‡ã€‚

æ­¤æ—¶æ¨¡å‹çš„å‘å‰æ‰©æ•£å’Œé€†å‘é‡‡æ ·è¿‡ç¨‹å°±æ˜¯åœ¨æ½œåœ¨ç©ºé—´è¿›è¡Œçš„ï¼Œå¦‚ä¸‹ï¼š

![image-20240423163310324](assets\image-20240423163310324.png)

å³ï¼š

- å‘å‰æ‰©æ•£ï¼šå¯¹æ½œåœ¨æ•°æ®æ·»åŠ å™ªå£°çš„è¿‡ç¨‹ã€‚
- é€†å‘é‡‡æ ·ï¼šä»æ½œåœ¨æ•°æ®ä¸­æ¶ˆé™¤å™ªå£°çš„è¿‡ç¨‹ã€‚

### æ¡ä»¶æ§åˆ¶

![image-20240423164719241](assets\image-20240423164719241.png)

ä»¥ä¸Šä¸ºæ·»åŠ æ–‡æœ¬æ§åˆ¶ä¿¡æ¯åï¼Œæ¨¡å‹é‡‡æ ·è¿è¡Œçš„æœºåˆ¶ã€‚è¿™é‡Œå°†æ–‡æœ¬ prompt ç»è¿‡$\ \tau_{\theta}$ (å¦‚ï¼šCLIP text-encoder)ç¼–è¯‘æˆç‰¹å¾å‘é‡ Text embedding å¹¶å°†å…¶ä½œä¸ºæ¨¡å‹çš„è¾“å…¥ï¼Œå¼•å¯¼æ¨¡å‹ç”Ÿæˆçš„ç»“æœã€‚

å½“ç„¶ï¼Œæ§åˆ¶ä¿¡æ¯ä¸æ­¢ç”±æ–‡æœ¬ï¼Œè¿˜æœ‰å›¾ç‰‡ä¿¡æ¯ã€è¯­ä¹‰å›¾ä¿¡æ¯ç­‰ã€‚å¹¶ä¸”ï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ  switch å¼€å…³æ¥æ¥æ”¶ä¸åŒç±»å‹çš„æ§åˆ¶ä¿¡æ¯ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹ç”Ÿæˆæ›´åŠ å¤šæ ·åŒ–çš„å›¾ç‰‡ã€‚å¦‚ä¸‹ï¼š

![image-20240423165624230](assets\image-20240423165624230.png)

è¿™é‡Œä½¿ç”¨çš„æ˜¯Classifier-free guidanceï¼Œå³å°†æ§åˆ¶ä¿¡æ¯åµŒå…¥åˆ°ç”Ÿæˆæ¨¡å‹å†…éƒ¨ï¼Œä»è€Œé—´æ¥å¼•å¯¼å›¾ç‰‡çš„ç”Ÿæˆç»“æœã€‚

### è®­ç»ƒè¿‡ç¨‹

![image-20240423173147304](assets\image-20240423173147304.png)

è¿™é‡Œæ²¡æœ‰ä»€ä¹ˆå˜åŒ–ï¼Œåªæ˜¯é¢„æµ‹å™ªå£°çš„å¯¹è±¡ç”±$\ x_t$ å˜ä¸ºäº†æ½œåœ¨æ•°æ®$\ z_t$ ï¼Œå¹¶ä¸”æ¨¡å‹ä¸­é¢å¤–æ·»åŠ äº†æ§åˆ¶ä¿¡æ¯ï¼Œä½œä¸ºè¾“å…¥ã€‚

### ç”Ÿæˆ/é‡‡æ ·è¿‡ç¨‹

![image-20240423173523526](assets\image-20240423173523526.png)

é‡‡æ ·è¿‡ç¨‹ä¹Ÿä¸å¤æ‚ï¼š

1. éšæœºé‡‡æ ·æ½œåœ¨é«˜æ–¯å™ªå£°$\ z_T$ï¼›
2. æ·»åŠ æ§åˆ¶ä¿¡æ¯å¹¶è½¬åŒ–ä¸ºç‰¹å¾å‘é‡ conditioning embedding;
3. é¢„æµ‹å™ªå£°$\ \epsilon_{\theta}(z_t, t, \tau_{\theta}(y))$ ï¼Œå¹¶æ±‚å‡ºé€†å‘è½¬æ¢æ ¸$\ p_{\theta}(z_{t-1}|z_t, t, \tau_{\theta}(y))$ çš„å‡å€¼ï¼›
4. é€šè¿‡$\ p_{\theta}(z_{t-1}|z_t, t, \tau_{\theta}(y))$ è®¡ç®—å‡º$\ z_{t-1}$ çš„å€¼ï¼›
5. å¦‚æ­¤åå¤ 3ã€4 æ­¥éª¤ï¼Œç›´åˆ°æ±‚å‡º$\ z_0$ã€‚è¿™é‡Œ$\ \tau_{\theta}(y)$ çš„å€¼æ˜¯å›ºå®šçš„ï¼Œä¸ä¼šéš$\ t$ çš„å˜åŒ–æ”¹å˜ï¼›
6. å°†$\ z_0$â€‹ å–‚å…¥ç¼–ç å™¨Dï¼Œå¾—åˆ°æœ€ç»ˆé‡‡æ ·å‡ºçš„å›¾åƒã€‚

## 3. ç¨³å®šæ‰©æ•£æ¨¡å‹ï¼ˆStable Diffusion Modelsï¼‰

ä»¥ä¸Šå°±æ˜¯LDMå‘å‰æ‰©æ•£å’Œé€†å‘é‡‡æ ·çš„å…¨è¿‡ç¨‹ã€‚Stable Diffusionå°±æ˜¯LDMçš„å¼€æºæ¨¡å‹ï¼Œå®ƒçš„å‘å‰æ‰©æ•£ä»¥åŠé‡‡æ ·è¿‡ç¨‹éƒ½æ˜¯æ²¡æœ‰å˜åŒ–ã€‚ä¸‹é¢ä»ä»£ç å»åˆ†æStable Diffusionæ¨ç†è¿‡ç¨‹ã€‚

### æ¨ç†è¿‡ç¨‹ä»£ç 

ä»£ç æ˜¯ä» diffusers ä¸­è·å–çš„ã€‚å…¶ä¸­å…³é”®ç»„ä»¶ä¸ºï¼štokenizer, text_encoder, vae, unet, schedulerã€‚è¿˜æœ‰å…¶å®ƒä¸é‡è¦çš„ç»„ä»¶ï¼šsafety_checker, feature_extractorã€‚ä¸‹é¢å¯¹å„ä¸ªç»„ä»¶è¿›è¡Œå¤§è‡´çš„è§£é‡Šï¼š

- tokenizerï¼šå°†æ–‡æœ¬è¾“å…¥è½¬åŒ–æˆtokens
- text_encoder: å°†tokensè½¬åŒ–æˆç‰¹å¾å‘é‡text_embeddingã€‚
- vae: VAE autoencoderï¼ŒåŒ…æ‹¬ç¼–ç å’Œè§£ç éƒ¨åˆ†ï¼Œè´Ÿè´£å¯¹å›¾ç‰‡è¿›è¡Œå‹ç¼©å’Œè¿˜åŸã€‚
- unet: è´Ÿè´£é¢„æµ‹å™ªå£°ã€‚
- scheduler: é€†å‘é‡‡æ ·çš„å®ç°æ–¹æ³•ï¼Œå³è®¡ç®—$\ z_t -> z_{t-1}$ ï¼Œå¯¹åº”ç€ DDPMã€DDIMã€ODEç­‰ä¸åŒçš„é™é‡‡æ ·å®ç°ã€‚
- safe_checker: æ£€æŸ¥ç”Ÿæˆçš„å›¾ç‰‡æ˜¯å¦å®‰å…¨ã€‚
- feature_extractor: å¯¹æ¡ä»¶å›¾ç‰‡ä¿¡æ¯è¿›è¡Œç‰¹å¾æå–ï¼Œä¹Ÿå°±æ˜¯å›¾ç”Ÿå›¾ (img2img)ã€‚

```python
def __init__(
    self,
    vae: AutoencoderKL,
    text_encoder: CLIPTextModel,
    tokenizer: CLIPTokenizer,
    unet: UNet2DConditionModel,
    scheduler: KarrasDiffusionSchedulers,
    safety_checker: StableDiffusionSafetyChecker,
    feature_extractor: CLIPImageProcessor,
    requires_safety_checker: bool = True,
):
    ...
```

æ¥ä¸‹æ¥æ˜¯æ ¸å¿ƒé€»è¾‘çš„å®ç°ï¼Œä»£ç åœ¨æ–¹æ³• `StableDiffusionPipeline::__call__` ä¸­:

```python
def __call__(
    self,
    prompt: Union[str, List[str]] = None,
    height: Optional[int] = None,
    width: Optional[int] = None,
    num_inference_steps: int = 50,
    guidance_scale: float = 7.5,
    negative_prompt: Optional[Union[str, List[str]]] = None,
    num_images_per_prompt: Optional[int] = 1,
    eta: float = 0.0,
    generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,
    latents: Optional[torch.FloatTensor] = None,
    prompt_embeds: Optional[torch.FloatTensor] = None,
    negative_prompt_embeds: Optional[torch.FloatTensor] = None,
    output_type: Optional[str] = "pil",
    return_dict: bool = True,
    callback: Optional[Callable[[int, int, torch.FloatTensor], None]] = None,
    callback_steps: int = 1,
    cross_attention_kwargs: Optional[Dict[str, Any]] = None,
):
    r"""
    Function invoked when calling the pipeline for generation.

    Args:
        prompt (`str` or `List[str]`, *optional*):
            The prompt or prompts to guide the image generation. If not defined, one has to pass `prompt_embeds`.
            instead.
        height (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor):
            The height in pixels of the generated image.
        width (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor):
            The width in pixels of the generated image.
        num_inference_steps (`int`, *optional*, defaults to 50):
            The number of denoising steps. More denoising steps usually lead to a higher quality image at the
            expense of slower inference.
        guidance_scale (`float`, *optional*, defaults to 7.5):
            Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).
            `guidance_scale` is defined as `w` of equation 2. of [Imagen
            Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >
            1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,
            usually at the expense of lower image quality.
        negative_prompt (`str` or `List[str]`, *optional*):
            The prompt or prompts not to guide the image generation. If not defined, one has to pass
            `negative_prompt_embeds` instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is
            less than `1`).
        num_images_per_prompt (`int`, *optional*, defaults to 1):
            The number of images to generate per prompt.
        eta (`float`, *optional*, defaults to 0.0):
            Corresponds to parameter eta (Î·) in the DDIM paper: https://arxiv.org/abs/2010.02502. Only applies to
            [`schedulers.DDIMScheduler`], will be ignored for others.
        generator (`torch.Generator` or `List[torch.Generator]`, *optional*):
            One or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)
            to make generation deterministic.
        latents (`torch.FloatTensor`, *optional*):
            Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image
            generation. Can be used to tweak the same generation with different prompts. If not provided, a latents
            tensor will ge generated by sampling using the supplied random `generator`.
        prompt_embeds (`torch.FloatTensor`, *optional*):
            Pre-generated text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not
            provided, text embeddings will be generated from `prompt` input argument.
        negative_prompt_embeds (`torch.FloatTensor`, *optional*):
            Pre-generated negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
            weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt` input
            argument.
        output_type (`str`, *optional*, defaults to `"pil"`):
            The output format of the generate image. Choose between
            [PIL](https://pillow.readthedocs.io/en/stable/): `PIL.Image.Image` or `np.array`.
        return_dict (`bool`, *optional*, defaults to `True`):
            Whether or not to return a [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] instead of a
            plain tuple.
        callback (`Callable`, *optional*):
            A function that will be called every `callback_steps` steps during inference. The function will be
            called with the following arguments: `callback(step: int, timestep: int, latents: torch.FloatTensor)`.
        callback_steps (`int`, *optional*, defaults to 1):
            The frequency at which the `callback` function will be called. If not specified, the callback will be
            called at every step.
        cross_attention_kwargs (`dict`, *optional*):
            A kwargs dictionary that if specified is passed along to the `AttentionProcessor` as defined under
            `self.processor` in
            [diffusers.cross_attention](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/cross_attention.py).

    Examples:

    Returns:
        [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] or `tuple`:
        [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] if `return_dict` is True, otherwise a `tuple.
        When returning a tuple, the first element is a list with the generated images, and the second element is a
        list of `bool`s denoting whether the corresponding generated image likely represents "not-safe-for-work"
        (nsfw) content, according to the `safety_checker`.
    """
    # 0. Default height and width to unet
    # unet ç½‘ç»œè¾“å…¥çš„å›¾åƒå°ºå¯¸ï¼Œä¹Ÿå°±æ˜¯æ½œç©ºé—´ Latent space çš„å°ºå¯¸
    height = height or self.unet.config.sample_size * self.vae_scale_factor
    width = width or self.unet.config.sample_size * self.vae_scale_factor

    # 1. Check inputs. Raise error if not correct
    # æ£€æŸ¥è¾“å…¥çš„åˆæ³•æ€§ï¼Œå¯ä»¥ä¸å…³æ³¨
    self.check_inputs(
        prompt, height, width, callback_steps, negative_prompt, prompt_embeds, negative_prompt_embeds
    )

    # 2. Define call parameters
    if prompt is not None and isinstance(prompt, str):
        batch_size = 1
    elif prompt is not None and isinstance(prompt, list):
        batch_size = len(prompt)
    else:
        batch_size = prompt_embeds.shape[0]

    device = self._execution_device
    # here `guidance_scale` is defined analog to the guidance weight `w` of equation (2)
    # of the Imagen paper: https://arxiv.org/pdf/2205.11487.pdf . `guidance_scale = 1`
    # corresponds to doing no classifier free guidance.
    # æ˜¯å¦å¯åŠ¨ classifier_free_guidance ç‰¹æ€§ï¼Œå¦‚æœå¯ç”¨çš„éœ€è¦åŒæ—¶æ‰§è¡Œå¸¦æ¡ä»¶çš„å™ªå£°é¢„æµ‹å’Œä¸å¸¦æ¡ä»¶çš„å™ªå£°é¢„æµ‹
    # æ³¨æ„ï¼Œè´Ÿæç¤ºè¯æ˜¯å¦ç”Ÿæ•ˆå’Œå®ƒç›¸å…³ï¼Œåªæœ‰å¯ç”¨ classifier_free_guidance è´Ÿæç¤ºè¯æ‰ä¼šç”Ÿæ•ˆï¼Œ
    # å¦åˆ™è´Ÿæç¤ºè¯ä¸èµ·ä½œç”¨ã€‚
    do_classifier_free_guidance = guidance_scale > 1.0

    # 3. Encode input prompt
    # å¯¹è¾“å…¥çš„æ–‡æœ¬Promptè¿›è¡Œç¼–ç å¤„ç†ï¼Œå†…éƒ¨å…¶å®æ˜¯è°ƒç”¨æ–‡æœ¬ç¼–ç å™¨è¿›è¡Œç¼–ç å¤„ç†
    # è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯è´Ÿæç¤ºè¯çš„å¤„ç†
    # å¦‚æœ do_classifier_free_guidance == Trueï¼Œè´Ÿæç¤ºè¯æ‰ä¼šç”Ÿæ•ˆï¼Œå¹¶èµ·æ˜¯å’Œæ­£æç¤ºè¯åœ¨batchç»´åº¦æ‹¼æ¥åœ¨ä¸€èµ·
    # prompt_embeds = torch.cat([negative_prompt_embeds, prompt_embeds])
    # ç¨åè§£é‡Šä¸ºä»€ä¹ˆ
    prompt_embeds = self._encode_prompt(
        prompt,
        device,
        num_images_per_prompt,
        do_classifier_free_guidance,
        negative_prompt,
        prompt_embeds=prompt_embeds,
        negative_prompt_embeds=negative_prompt_embeds,
    )

    # 4. Prepare timesteps
    self.scheduler.set_timesteps(num_inference_steps, device=device)
    timesteps = self.scheduler.timesteps

    # 5. Prepare latent variables
    # unet ç½‘ç»œè¾“å…¥æ”¯æŒçš„ channels æ•°é‡
    num_channels_latents = self.unet.config.in_channels
    # è®¾ç½®é™å™ªè¿‡ç¨‹çš„åˆå§‹åŒ–éšæœºé«˜æ–¯å™ªå£°ï¼Œä¹Ÿå°±æ˜¯ latent åˆå§‹åŒ–
    latents = self.prepare_latents(
        batch_size * num_images_per_prompt,
        num_channels_latents,
        height,
        width,
        prompt_embeds.dtype,
        device,
        generator,
        latents,
    )

    # 6. Prepare extra step kwargs. TODO: Logic should ideally just be moved out of the pipeline
    extra_step_kwargs = self.prepare_extra_step_kwargs(generator, eta)

    # 7. Denoising loop
    num_warmup_steps = len(timesteps) - num_inference_steps * self.scheduler.order
    with self.progress_bar(total=num_inference_steps) as progress_bar:
        for i, t in enumerate(timesteps):
            # expand the latents if we are doing classifier free guidance
            # è¿™é‡Œåœ¨ batch ç»´åº¦æ”¾å¤§ä¸¤å€ï¼Œæ˜¯ä¸ºäº†åœ¨ä¸€ä¸ªbatchä¸­åŒæ—¶å¤„ç†å¾—åˆ°æœ‰æ¡ä»¶å™ªå£°é¢„æµ‹å’Œæ— æ¡ä»¶å™ªå£°é¢„æµ‹
            latent_model_input = torch.cat([latents] * 2) if do_classifier_free_guidance else latents
            latent_model_input = self.scheduler.scale_model_input(latent_model_input, t)

            # predict the noise residual
            # é¢„æµ‹å™ªå£°ï¼Œå½“ç„¶è¿™ä¸ªè¿‡ç¨‹æ˜¯åœ¨æ½œç©ºé—´ latent space è¿›è¡Œçš„
            noise_pred = self.unet(
                latent_model_input,
                t,
                encoder_hidden_states=prompt_embeds,
                cross_attention_kwargs=cross_attention_kwargs,
                return_dict=False,
            )[0]

            # perform guidance
            if do_classifier_free_guidance:
                # åœ¨batchç»´åº¦ä¸€åˆ†ä¸ºäºŒï¼Œå‰ä¸€åŠä½œä¸ºæ— æ¡ä»¶é¢„æµ‹å™ªå£°ï¼Œåä¸€è¾¹æ˜¯æœ‰æ¡ä»¶é¢„æµ‹å™ªå£°
                noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)
                # æ ¹æ®  classifier free guidance å…¬å¼è¿›è¡ŒåŠ æƒæ±‚å’Œ
                noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)

            # compute the previous noisy sample x_t -> x_t-1
            # ä½¿ç”¨ scheduler è¿›è¡Œé™å™ªå¤„ç†ï¼Œè¿™é‡Œ scheduler å…¶å®å°±æ˜¯ä¸åŒé™å™ªé‡‡æ ·ç®—æ³•çš„å®ç°ï¼Œå¯ä»¥æœ‰å¤šç§ä¸åŒå®ç°ï¼Œæ¯”å¦‚ DDPMã€DDIMã€ODEç­‰å„ç§é‡‡æ ·ç®—æ³•
            latents = self.scheduler.step(noise_pred, t, latents, **extra_step_kwargs, return_dict=False)[0]

            # call the callback, if provided
            if i == len(timesteps) - 1 or ((i + 1) > num_warmup_steps and (i + 1) % self.scheduler.order == 0):
                progress_bar.update()
                if callback is not None and i % callback_steps == 0:
                    callback(i, t, latents)
    # æœ€åï¼Œè¿˜éœ€è¦ç”¨ vae çš„è§£ç å™¨ï¼ŒæŠŠ latent è§£ç æˆåŸå°ºå¯¸çš„å›¾åƒ
    if output_type == "latent":
        image = latents
        has_nsfw_concept = None
    elif output_type == "pil":
        # 8. Post-processing
        image = self.decode_latents(latents)

        # 9. Run safety checker
        image, has_nsfw_concept = self.run_safety_checker(image, device, prompt_embeds.dtype)

        # 10. Convert to PIL
        image = self.numpy_to_pil(image)
    else:
        # 8. Post-processing
        image = self.decode_latents(latents)

        # 9. Run safety checker
        image, has_nsfw_concept = self.run_safety_checker(image, device, prompt_embeds.dtype)

    # Offload last model to CPU
    if hasattr(self, "final_offload_hook") and self.final_offload_hook is not None:
        self.final_offload_hook.offload()

    if not return_dict:
        return (image, has_nsfw_concept)

    return StableDiffusionPipelineOutput(images=image, nsfw_content_detected=has_nsfw_concept)
```

åœ¨ä»£ç ä¸­ï¼ŒUNetè¾“å‡ºçš„2ä¸ªbatchï¼Œä¸€ä¸ªæ˜¯æœ‰æ— æ¡ä»¶é¢„æµ‹ï¼Œå¦ä¸€ä¸ªæ˜¯æœ‰æ¡ä»¶é¢„æµ‹ã€‚æœ‰æ¡ä»¶é¢„æµ‹çš„æ¡ä»¶ä¿¡æ¯å°±æ˜¯$\ prompt\_embed$ï¼Œå³æ­£é¢æç¤ºå»ï¼›æ— æ¡ä»¶é¢„æµ‹å…¶å®ä¹Ÿç”±æ¡ä»¶ä¿¡æ¯$\ negative\_prompt\_embed$ï¼Œè¿™é‡Œæ— æ¡ä»¶é¢„æµ‹æ˜¯å°†å…¶å®è´Ÿé¢æç¤ºè¯å’Œ classifier_free_guidance ç³…åˆåˆ°äº†ä¸€èµ·ã€‚åœ¨ä¸Šè¿°ä»£ç ä¸­å™ªå£°çš„é¢„æµ‹ç»“æœä¸ºï¼š

````python
noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)
````

è¿™ä¸ªå¯ä»¥æ ¹æ®å…¬å¼(8)è½¬æ¢å¾—åˆ°ï¼š
$$
\begin{aligned}
\nabla_{x_t}\log p(x_t|y) &= \lambda \nabla_{x_t}\log p(x_t|y) + (1-\lambda)\nabla_{x_t}\log p(x_t)\\
&= \nabla_{x_t}\log p(x_t) + \lambda(\nabla_{x_t}\log p(x_t|y) - \nabla_{x_t}\log p(x_t)) \\
&= noise\_pred\_uncond \ +\  guidance\_scale\ *\ (noise\_pred\_text\ -\ noise\_pred\_uncond)
\end{aligned}
$$
åœ¨è¿™ä¸ªæ¨¡å‹ä¸­ `noise_pred_uncond` æ˜¯æŒ‡å¯¼æ¨¡å‹ç”Ÿæˆè´Ÿé¢æç¤ºè¯çš„å†…å®¹ï¼Œ`noise_pred_text`æ˜¯æŒ‡å¯¼æ¨¡å‹ç”Ÿæˆæ­£é¢æç¤ºè¯çš„å†…å®¹ï¼Œåœ¨ä»£ç ä¸­å½“`guidance_scale`çš„å€¼å¤§äº 1 æ—¶ï¼Œ`noise_pred_uncond`çš„æƒé‡å°±ä¸ºè´Ÿæ•°ï¼Œå°±è¯´æ˜å°½é‡é¿å…ç”Ÿæˆè´Ÿé¢æç¤ºè¯çš„å†…å®¹ã€‚
